import argparse
import time
from typing import Union, Optional

import cv2
import numpy as np
from ultralytics import YOLO

# -----------------------------
# RealSense import
# -----------------------------
try:
    import pyrealsense2 as rs
    REALSENSE_AVAILABLE = True
except ImportError:
    REALSENSE_AVAILABLE = False
    print("ê²½ê³ : pyrealsense2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. RealSense ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# -----------------------------
# STT / TTS
# -----------------------------
import speech_recognition as sr
from gtts import gTTS
import os


# =============================================================
# 0. ì¡°ì‚¬ ì œê±° / í´ë˜ìŠ¤ ë§¤í•‘ / 9ë¶„í•  ìœ„ì¹˜ í…ìŠ¤íŠ¸
# =============================================================
particles = [
    "ì´ë‘", "ë‘", "í•˜ê³ ", "ê³¼", "ì™€",
    "ì—ì„œ", "ìœ¼ë¡œ", "ë¡œ",
    "ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì—"
]

# laptop / notebook ì œê±°í•œ ë²„ì „
YOLO_CLASSES = [
    "airpods", "cell phone", "tissue", "mouse",
    "bottle", "glasses", "jelly", "card", "wallet",
    "lipbalm", "remocon", "pen", "applewatch"
]

# ìì—°ì–´ â†’ YOLO í´ë˜ìŠ¤ ë§¤í•‘
SYNONYMS = {
    "ì—ì–´íŒŸ": "airpods",
    "ì´ì–´í°": "airpods",

    "í•¸ë“œí°": "cell phone",
    "íœ´ëŒ€í°": "cell phone",
    "í°": "cell phone",

    "í‹°ìŠˆ": "tissue",
    "íœ´ì§€": "tissue",

    "ë§ˆìš°ìŠ¤": "mouse",

    "ë¬¼ë³‘": "bottle",
    "ë³´í‹€": "bottle",

    "ì•ˆê²½": "glasses",
    "ì„ ê¸€ë¼ìŠ¤": "glasses",

    "ì ¤ë¦¬": "jelly",

    "ì¹´ë“œ": "card",
    "ì‹ ìš©ì¹´ë“œ": "card",

    "ì§€ê°‘": "wallet",

    "ë¦½ë°¤": "lipbalm",
    "ë¦½": "lipbalm",

    "ë¦¬ëª¨ì½˜": "remocon",
    "ë¦¬ëª¨ì»¨": "remocon",

    "íœ": "pen",
    "ë³¼íœ": "pen",

    "ì• í”Œì›Œì¹˜": "applewatch",
    "ì›Œì¹˜": "applewatch"
}

def split_particle(word: str):
    for p in particles:
        if word.endswith(p):
            return [word[:-len(p)], p]
    return [word]

def remove_particle(word: str):
    for p in particles:
        if word.endswith(p):
            return word[:-len(p)]
    return word

def map_to_class(text: str):
    tokens = []
    for w in text.split():
        tokens.extend(split_particle(w))

    for token in tokens:
        stem = remove_particle(token)
        if stem in SYNONYMS:
            return SYNONYMS[stem]
        if stem in YOLO_CLASSES:
            return stem
    return None


# -----------------------------
# 9ë¶„í•  ìœ„ì¹˜ ë¬¸êµ¬
# -----------------------------
GRID_TEXT = {
    1: "TVì™€ ì„œëì¥ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    2: "ì„œëì¥ê³¼ ì¹¨ëŒ€ ì‚¬ì´ì— ìˆìŠµë‹ˆë‹¤.",
    3: "ì¹¨ëŒ€ì™€ ì†ŒíŒŒ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    4: "TV ì•ì— ìˆìŠµë‹ˆë‹¤.",
    5: "ì •ê°€ìš´ë°ì— ìˆìŠµë‹ˆë‹¤.",
    6: "ì†ŒíŒŒ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    7: "ì™€ì¸ì…€ëŸ¬ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    8: "ì¤‘ì•™ ì•„ë˜ìª½ì— ìˆìŠµë‹ˆë‹¤.",
    9: "ì†ŒíŒŒ ì™¼ìª½ ì•ì— ìˆìŠµë‹ˆë‹¤."
}

def grid_region(cx, cy, w, h):
    col = int(cx // (w/3))
    row = int(cy // (h/3))
    return row * 3 + col + 1


# =============================================================
# 9ë¶„í•  ê·¸ë¦¬ë“œ ê·¸ë¦¬ê¸°
# =============================================================
def draw_grid(frame):
    h, w = frame.shape[:2]
    color = (0,255,0)
    cv2.line(frame, (w//3, 0), (w//3, h), color, 2)
    cv2.line(frame, (2*w//3, 0), (2*w//3, h), color, 2)
    cv2.line(frame, (0, h//3), (w, h//3), color, 2)
    cv2.line(frame, (0, 2*h//3), (w, 2*h//3), color, 2)
    return frame


# =============================================================
# STT / TTS
# =============================================================
def stt_listen():
    r = sr.Recognizer()
    with sr.Microphone() as mic:
        print("ğŸ¤ STT ëŒ€ê¸°ì¤‘... ë§í•˜ì„¸ìš”.")
        audio = r.listen(mic)

    try:
        text = r.recognize_google(audio, language='ko-KR')
        print("ğŸ—£ï¸ ì¸ì‹:", text)
        return text
    except:
        print("âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
        return ""

def tts_speak(text):
    t = gTTS(text=text, lang='ko')
    t.save("tts_out.mp3")
    os.system("mpg123 tts_out.mp3")


# =============================================================
# YOLO ì½”ë“œ ê¸°ë³¸ ìœ ì§€
# =============================================================
def parse_args() -> argparse.Namespace:
    from pathlib import Path
    project_root = Path(__file__).parent.absolute()
    default_weights = project_root / "weights" / "best.pt"
    if not default_weights.exists():
        default_weights = project_root / "weights" / "yolov8l.pt"

    parser = argparse.ArgumentParser(description="YOLOv8 ì‹¤ì‹œê°„ ì¶”ë¡ ")
    parser.add_argument("--weights", type=str, default=str(default_weights))
    parser.add_argument("--source", type=str, default="realsense")
    parser.add_argument("--imgsz", type=int, default=1280)
    parser.add_argument("--conf", type=float, default=0.5)
    parser.add_argument("--iou", type=float, default=0.7)
    parser.add_argument("--device", type=str, default="cpu")
    parser.add_argument("--show", action="store_true")
    return parser.parse_args()


# =============================================================
# RealSense ì´ˆê¸°í™”
# =============================================================
def init_realsense() -> Optional[rs.pipeline]:
    if not REALSENSE_AVAILABLE:
        print("âŒ pyrealsense2 ì—†ìŒ â†’ RealSense ë¶ˆê°€")
        return None
    try:
        pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 1280,720, rs.format.bgr8, 30)
        pipeline.start(config)
        print("âœ… RealSense ì—°ê²° ì„±ê³µ")
        return pipeline
    except Exception as e:
        print("âŒ RealSense ì—°ê²° ì‹¤íŒ¨:", e)
        return None

def get_frame_realsense(pipeline):
    try:
        frames = pipeline.wait_for_frames()
        f = frames.get_color_frame()
        if f:
            return np.asanyarray(f.get_data())
    except:
        return None
    return None


# =============================================================
# ë©”ì¸ ì‹¤í–‰ë¶€
# =============================================================
def main():
    args = parse_args()
    model = YOLO(args.weights)

    use_rs = args.source.lower() in ["realsense","rs","d435i"]
    pipeline = None
    cap = None

    # -----------------------------
    # RealSense: ì„±ê³µí•  ë•Œê¹Œì§€ ë¬´í•œ ì¬ì‹œë„
    # -----------------------------
    if use_rs:
        while pipeline is None:
            print("ğŸ”„ RealSense ì—°ê²° ì‹œë„ì¤‘...")
            pipeline = init_realsense()
            if pipeline is None:
                print("âŒ ì—°ê²° ì‹¤íŒ¨! 5ì´ˆ í›„ ì¬ì‹œë„â€¦")
                time.sleep(5)
        print("âœ… RealSense ìµœì¢… ì—°ê²° ì„±ê³µ!")

    else:
        cap = cv2.VideoCapture(to_int_if_digit(args.source))

    target_object = None

    # -----------------------------
    # ë©”ì¸ ë£¨í”„
    # -----------------------------
    try:
        while True:

            if use_rs:
                frame = get_frame_realsense(pipeline)
                ok = frame is not None
            else:
                ok, frame = cap.read()

            if not ok:
                continue

            fh, fw = frame.shape[:2]

            results = model.predict(
                frame,
                imgsz=args.imgsz,
                conf=args.conf,
                iou=args.iou,
                verbose=False
            )

            annotated = results[0].plot()
            annotated = draw_grid(annotated)

            key = cv2.waitKey(1) & 0xFF

            # -----------------------------
            # S í‚¤ â†’ ìŒì„± ì¸ì‹
            # -----------------------------
            if key == ord('s'):
                text = stt_listen()
                target_object = map_to_class(text)

                if not target_object:
                    tts_speak("ë¬´ìŠ¨ ë¬¼ê±´ì¸ì§€ ëª¨ë¥´ê² ì–´ìš”.")
                else:
                    print("ğŸ¯ ì°¾ëŠ” ê°ì²´:", target_object)

            # -----------------------------
            # YOLO íƒì§€ì—ì„œ ë¬¼ê±´ ì°¾ê¸°
            # -----------------------------
            if target_object:
                boxes = results[0].boxes
                if boxes:
                    for box in boxes:
                        name = results[0].names[int(box.cls[0])]
                        if name == target_object:
                            x1, y1, x2, y2 = box.xyxy[0]
                            cx = (x1+x2)/2
                            cy = (y1+y2)/2

                            region = grid_region(cx, cy, fw, fh)
                            speak_text = f"{target_object}ì€ {GRID_TEXT.get(region)}"
                            print("ğŸ“¢", speak_text)
                            tts_speak(speak_text)

                            target_object = None
                            break

            if args.show:
                cv2.imshow("YOLO + Grid", annotated)

            if key == 27:
                break

    finally:
        if pipeline:
            pipeline.stop()
        if cap:
            cap.release()
        cv2.destroyAllWindows()


# =============================================================
if __name__ == "__main__":
    main()
