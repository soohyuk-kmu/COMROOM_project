import argparse
import time
from typing import Union, Optional

import cv2
import numpy as np
from ultralytics import YOLO

# -----------------------------
# RealSense import
# -----------------------------
try:
    import pyrealsense2 as rs
    REALSENSE_AVAILABLE = True
except ImportError:
    REALSENSE_AVAILABLE = False
    print("ê²½ê³ : pyrealsense2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. RealSense ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# -----------------------------
# STT / TTS
# -----------------------------
import speech_recognition as sr
from gtts import gTTS
import os


# =============================================================
# 0. ì¡°ì‚¬ ì œê±° / í´ë˜ìŠ¤ ë§¤í•‘ / 9ë¶„í•  ìœ„ì¹˜ í…ìŠ¤íŠ¸
# =============================================================
particles = [
    "ì´ë‘","ë‘","í•˜ê³ ","ê³¼","ì™€",
    "ì—ì„œ","ìœ¼ë¡œ","ë¡œ",
    "ì€","ëŠ”","ì´","ê°€","ì„","ë¥¼","ì—"
]

def strip_particle(word):
    for p in particles:
        if word.endswith(p):
            return word[:-len(p)]
    return word

YOLO_CLASSES = [
    "airpods","cell phone","tissue","mouse","laptop","bottle",
    "glasses","jelly","card","wallet","lipbalm","notebook",
    "remocon","pen","carkey"
]

SYNONYMS = {
    "í•¸ë“œí°": "cell phone",
    "í°": "cell phone",
    "íœ´ì§€": "tissue",
    "ë…¸íŠ¸ë¶": "laptop",
    "ì±…": "notebook",
    "ê³µì±…": "notebook",
    "ë¦¬ëª¨ì½˜": "remocon"
}

def map_to_class(text: str):
    words = text.split()
    for w in words:
        stem = strip_particle(w)
        if stem in SYNONYMS:
            return SYNONYMS[stem]
        if stem in YOLO_CLASSES:
            return stem
    return None


# -----------------------------
# 9ë¶„í•  ìœ„ì¹˜ ë¬¸êµ¬
# -----------------------------
GRID_TEXT = {
    1: "TVì™€ ì„œëì¥ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    2: "ì„œëì¥ê³¼ ì¹¨ëŒ€ ì‚¬ì´ì— ìˆìŠµë‹ˆë‹¤.",
    3: "ì¹¨ëŒ€ì™€ ì†ŒíŒŒ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    4: "TV ì•ì— ìˆìŠµë‹ˆë‹¤.",
    5: "ì •ê°€ìš´ë°ì— ìˆìŠµë‹ˆë‹¤.",
    6: "ì†ŒíŒŒ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    7: "ì™€ì¸ì…€ëŸ¬ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    8: "ì¤‘ì•™ ì•„ë˜ìª½ì— ìˆìŠµë‹ˆë‹¤.",
    9: "ì†ŒíŒŒ ì™¼ìª½ ì•ì— ìˆìŠµë‹ˆë‹¤."
}

def grid_region(cx, cy, w, h):
    col = int(cx // (w/3))
    row = int(cy // (h/3))
    return row * 3 + col + 1


# =============================================================
# 1. ì‹œê°í™”ìš© 9ë¶„í•  ê·¸ë¦¬ë“œ
# =============================================================
def draw_grid(frame):
    h, w = frame.shape[:2]
    w1 = w // 3
    w2 = 2 * w // 3
    h1 = h // 3
    h2 = 2 * h // 3

    color = (0,255,0)
    cv2.line(frame, (w1, 0), (w1, h), color, 2)
    cv2.line(frame, (w2, 0), (w2, h), color, 2)
    cv2.line(frame, (0, h1), (w, h1), color, 2)
    cv2.line(frame, (0, h2), (w, h2), color, 2)
    return frame


# =============================================================
# 2. STT / TTS
# =============================================================
def stt_listen():
    r = sr.Recognizer()
    with sr.Microphone() as mic:
        print("ğŸ¤ STT ëŒ€ê¸°ì¤‘... ë§í•˜ì„¸ìš”.")
        audio = r.listen(mic)

    try:
        text = r.recognize_google(audio, language='ko-KR')
        print("ğŸ—£ï¸ ì¸ì‹:", text)
        return text
    except:
        print("âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
        return ""

def tts_speak(text):
    t = gTTS(text=text, lang='ko')
    t.save("tts_out.mp3")
    os.system("mpg123 tts_out.mp3")


# =============================================================
# 3. ë„ˆê°€ ì¤€ YOLO ì½”ë“œ ê¸°ë°˜ ê·¸ëŒ€ë¡œ ìœ ì§€
# =============================================================
def parse_args() -> argparse.Namespace:
    from pathlib import Path
    
    project_root = Path(__file__).parent.absolute()
    default_weights = project_root / "weights" / "best.pt"
    if not default_weights.exists():
        default_weights = project_root / "weights" / "yolov8l.pt"
    
    parser = argparse.ArgumentParser(description="YOLOv8 ì‹¤ì‹œê°„ ì¶”ë¡ ")

    parser.add_argument("--weights", type=str, default=str(default_weights))
    parser.add_argument("--source", type=str, default="realsense")
    parser.add_argument("--imgsz", type=int, default=1280)
    parser.add_argument("--conf", type=float, default=0.5)
    parser.add_argument("--iou", type=float, default=0.7)
    parser.add_argument("--device", type=str, default="cpu")
    parser.add_argument("--save", type=str, default="")
    parser.add_argument("--show", action="store_true")
    parser.add_argument("--fps", action="store_true")
    parser.add_argument("--log-every", type=int, default=1)
    parser.add_argument("--homography", type=str, default="")
    return parser.parse_args()


def to_int_if_digit(text: str) -> Union[int, str]:
    return int(text) if text.isdigit() else text


def load_homography(path: str) -> Union[np.ndarray, None]:
    if not path:
        return None
    try:
        if path.lower().endswith(".npy"):
            H = np.load(path)
        else:
            import yaml
            with open(path, "r") as f:
                data = yaml.safe_load(f)
            H = np.asarray(data.get("H"), dtype=np.float64)
        if H.shape == (3,3):
            return H
    except:
        pass
    print("í˜¸ëª¨ê·¸ë˜í”¼ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return None


# -----------------------------
# RealSense ì´ˆê¸°í™”
# -----------------------------
def init_realsense() -> Optional[rs.pipeline]:
    if not REALSENSE_AVAILABLE:
        print("âŒ pyrealsense2ê°€ ì—†ìŒ")
        return None
    try:
        pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 1280,720, rs.format.bgr8,30)
        config.enable_stream(rs.stream.depth, 1280,720, rs.format.z16,30)
        pipeline.start(config)
        print("âœ… RealSense ì—°ê²° ì„±ê³µ")
        return pipeline
    except Exception as e:
        print("âŒ RealSense ì—°ê²° ì‹¤íŒ¨:", e)
        return None


def get_frame_realsense(pipeline):
    try:
        frames = pipeline.wait_for_frames()
        f = frames.get_color_frame()
        if f: return np.asanyarray(f.get_data())
    except:
        pass
    return None


# =============================================================
# 4. ë©”ì¸
# =============================================================
def main():
    args = parse_args()

    model = YOLO(args.weights)
    H = load_homography(args.homography)

    # -----------------------------
    # ì¹´ë©”ë¼ ì„ íƒ
    # -----------------------------
    use_rs = args.source.lower() in ["realsense","rs","d435i"]
    pipeline = None
    cap = None

    if use_rs:
        pipeline = init_realsense()
        if pipeline is None:
            print("âš ï¸ RealSense ì‚¬ìš© ë¶ˆê°€ â†’ ì›¹ìº ìœ¼ë¡œ ì „í™˜")
            use_rs = False
            cap = cv2.VideoCapture(0)
    else:
        source = to_int_if_digit(args.source)
        cap = cv2.VideoCapture(source)

    # -----------------------------
    # VideoWriter ì¤€ë¹„
    # -----------------------------
    writer = None
    prev_time = time.time()
    initialized_size = False
    frame_idx = 0

    target_object = None  # STTë¡œ ìš”ì²­ëœ YOLO í´ë˜ìŠ¤

    # =============================================================
    # ë£¨í”„ ì‹œì‘
    # =============================================================
    try:
        while True:

            # -----------------------------
            # í”„ë ˆì„ ì–»ê¸°
            # -----------------------------
            if use_rs:
                frame = get_frame_realsense(pipeline)
                ok = frame is not None
            else:
                ok, frame = cap.read()

            if not ok or frame is None:
                break

            frame_idx += 1
            fh, fw = frame.shape[:2]

            # 9ë¶„í•  ê·¸ë¦¬ë“œ ì‹œê°í™”
            frame_show = draw_grid(frame.copy())

            # -----------------------------
            # YOLO Predict
            # -----------------------------
            results = model.predict(
                frame,
                imgsz=args.imgsz,
                conf=args.conf,
                iou=args.iou,
                device=args.device,
                verbose=False
            )
            annotated = results[0].plot()

            # -----------------------------
            # S í‚¤ â†’ STT ì‹¤í–‰
            # -----------------------------
            key = cv2.waitKey(1)
            if key == ord('s'):
                text = stt_listen()
                target_object = map_to_class(text)

                if not target_object:
                    tts_speak("ë¬´ìŠ¨ ë¬¼ê±´ì¸ì§€ ëª¨ë¥´ê² ì–´ìš”.")
                else:
                    print("ğŸ¯ ì°¾ëŠ” ê°ì²´:", target_object)

            # -----------------------------
            # YOLO ë‚´ë¶€ì—ì„œ target_object ì°¾ê¸°
            # -----------------------------
            if target_object:
                det_boxes = results[0].boxes
                if det_boxes is not None:
                    for box in det_boxes:
                        name = results[0].names[int(box.cls[0])]
                        if name == target_object:
                            x1, y1, x2, y2 = box.xyxy[0]
                            cx = (x1+x2)/2
                            cy = (y1+y2)/2

                            region = grid_region(cx, cy, fw, fh)
                            speak_text = f"{target_object}ì€ {GRID_TEXT[region]}"
                            print("ğŸ“¢", speak_text)
                            tts_speak(speak_text)

                            target_object = None
                            break

            # -----------------------------
            # í™”ë©´ ì¶œë ¥
            # -----------------------------
            if args.show:
                cv2.imshow("YOLO + Grid", annotated)

            if key == 27:
                break

    finally:
        if pipeline is not None:
            pipeline.stop()
        if cap is not None:
            cap.release()
        cv2.destroyAllWindows()


# =============================================================
if __name__ == "__main__":
    main()
