import argparse
import time
import threading
from typing import Optional

import cv2
import numpy as np
from ultralytics import YOLO

# -----------------------------
# RealSense import
# -----------------------------
try:
    import pyrealsense2 as rs
    REALSENSE_AVAILABLE = True
except ImportError:
    REALSENSE_AVAILABLE = False
    print("ê²½ê³ : pyrealsense2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. RealSense ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# -----------------------------
# STT / TTS
# -----------------------------
import speech_recognition as sr
from gtts import gTTS
import os


# =============================================================
# ì¡°ì‚¬ ì œê±° / í´ë˜ìŠ¤ ë§¤í•‘
# =============================================================
particles = [
    "ì´ë‘", "ë‘", "í•˜ê³ ", "ê³¼", "ì™€",
    "ì—ì„œ", "ìœ¼ë¡œ", "ë¡œ",
    "ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì—"
]

YOLO_CLASSES = [
    "airpods", "cell phone", "tissue", "mouse",
    "bottle", "glasses", "jelly", "card", "wallet",
    "lipbalm", "remocon", "pen", "applewatch"
]

SYNONYMS = {
    "ì—ì–´íŒŸ": "airpods",
    "ì´ì–´í°": "airpods",
    "í•¸ë“œí°": "cell phone",
    "íœ´ëŒ€í°": "cell phone",
    "í°": "cell phone",
    "í‹°ìŠˆ": "tissue",
    "íœ´ì§€": "tissue",
    "ë§ˆìš°ìŠ¤": "mouse",
    "ë¬¼ë³‘": "bottle",
    "ë³´í‹€": "bottle",
    "ì•ˆê²½": "glasses",
    "ì„ ê¸€ë¼ìŠ¤": "glasses",
    "ì ¤ë¦¬": "jelly",
    "ì¹´ë“œ": "card",
    "ì‹ ìš©ì¹´ë“œ": "card",
    "ì§€ê°‘": "wallet",
    "ë¦½ë°¤": "lipbalm",
    "ë¦½": "lipbalm",
    "ë¦¬ëª¨ì½˜": "remocon",
    "ë¦¬ëª¨ì»¨": "remocon",
    "íœ": "pen",
    "ë³¼íœ": "pen",
    "ì• í”Œì›Œì¹˜": "applewatch",
    "ì›Œì¹˜": "applewatch"
}

def split_particle(word: str):
    for p in particles:
        if word.endswith(p):
            return [word[:-len(p)], p]
    return [word]

def remove_particle(word: str):
    for p in particles:
        if word.endswith(p):
            return word[:-len(p)]
    return word

def map_to_class(text: str):
    tokens = []
    for w in text.split():
        tokens.extend(split_particle(w))

    for token in tokens:
        stem = remove_particle(token)
        if stem in SYNONYMS:
            return SYNONYMS[stem]
        if stem in YOLO_CLASSES:
            return stem
    return None


# =============================================================
# 9ë¶„í•  ì•ˆë‚´ (í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©)
# =============================================================
GRID_TEXT = {
    1: "TVì™€ ì„œëì¥ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    2: "ì„œëì¥ê³¼ ì¹¨ëŒ€ ì‚¬ì´ì— ìˆìŠµë‹ˆë‹¤.",
    3: "ì¹¨ëŒ€ì™€ ì†ŒíŒŒ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    4: "TV ì•ì— ìˆìŠµë‹ˆë‹¤.",
    5: "ì •ê°€ìš´ë°ì— ìˆìŠµë‹ˆë‹¤.",
    6: "ì†ŒíŒŒ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    7: "ì™€ì¸ì…€ëŸ¬ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    8: "ì¤‘ì•™ ì•„ë˜ìª½ì— ìˆìŠµë‹ˆë‹¤.",
    9: "ì†ŒíŒŒ ì™¼ìª½ ì•ì— ìˆìŠµë‹ˆë‹¤."
}

def grid_region(cx, cy, w, h):
    col = int(cx // (w/3))
    row = int(cy // (h/3))
    return row * 3 + col + 1


# =============================================================
# STT / TTS
# =============================================================
def stt_listen():
    r = sr.Recognizer()
    with sr.Microphone() as mic:
        print("ğŸ¤ STT ëŒ€ê¸°ì¤‘â€¦ ë§í•˜ì„¸ìš”.")
        audio = r.listen(mic)

    try:
        text = r.recognize_google(audio, language='ko-KR')
        print("ğŸ—£ ì¸ì‹:", text)
        return text
    except:
        print("âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
        return ""

def tts_speak(text):
    t = gTTS(text=text, lang='ko')
    t.save("tts_out.mp3")
    os.system("mpg123 tts_out.mp3")


# =============================================================
# YOLO
# =============================================================
def parse_args() -> argparse.Namespace:
    from pathlib import Path
    project_root = Path(__file__).parent.absolute()
    default_weights = project_root / "weights" / "best.pt"
    if not default_weights.exists():
        default_weights = project_root / "weights" / "yolov8l.pt"

    parser = argparse.ArgumentParser()
    parser.add_argument("--weights", type=str, default=str(default_weights))
    parser.add_argument("--source", type=str, default="realsense")
    parser.add_argument("--imgsz", type=int, default=1280)
    parser.add_argument("--conf", type=float, default=0.5)
    parser.add_argument("--iou", type=float, default=0.7)
    parser.add_argument("--device", type=str, default="cpu")
    parser.add_argument("--show", action="store_true")
    return parser.parse_args()


# =============================================================
# RealSense
# =============================================================
def init_realsense() -> Optional[rs.pipeline]:
    if not REALSENSE_AVAILABLE:
        print("âŒ pyrealsense2 ì—†ìŒ â†’ RealSense ë¶ˆê°€")
        return None

    try:
        pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)
        pipeline.start(config)
        print("âœ… RealSense ì—°ê²° ì„±ê³µ!")
        return pipeline
    except Exception as e:
        print("âŒ RealSense ì—°ê²° ì‹¤íŒ¨:", e)
        return None


def get_frame_realsense(pipeline):
    try:
        frames = pipeline.wait_for_frames()
        f = frames.get_color_frame()
        if f:
            return np.asanyarray(f.get_data())
    except:
        return None
    return None


# =============================================================
# STT ìŠ¤ë ˆë“œ í•¨ìˆ˜
# =============================================================
def stt_thread(result_holder):
    text = stt_listen()
    cls = map_to_class(text)

    if not cls:
        tts_speak("ë¬´ìŠ¨ ë¬¼ê±´ì¸ì§€ ëª¨ë¥´ê² ì–´ìš”.")
        result_holder["target"] = None
    else:
        print("ğŸ¯ ì°¾ëŠ” ê°ì²´:", cls)
        result_holder["target"] = cls

    result_holder["running"] = False


# =============================================================
# MAIN
# =============================================================
def main():
    args = parse_args()
    model = YOLO(args.weights)

    use_rs = args.source.lower() in ["realsense", "rs", "d435i"]

    pipeline = None
    cap = None

    # RealSense ë¬´í•œ ì¬ì‹œë„
    if use_rs:
        while pipeline is None:
            print("ğŸ”„ RealSense ì—°ê²° ì‹œë„ì¤‘â€¦")
            pipeline = init_realsense()
            if pipeline is None:
                print("âŒ ì‹¤íŒ¨. 5ì´ˆ í›„ ì¬ì‹œë„â€¦")
                time.sleep(5)
        print("ğŸ‰ RealSense ìµœì¢… ì—°ê²° ì„±ê³µ!")
    else:
        cap = cv2.VideoCapture(args.source)

    # STT ìƒíƒœ ì €ì¥
    stt_state = {"target": None, "running": False}

    try:
        while True:

            # ----- í”„ë ˆì„ -----
            if use_rs:
                frame = get_frame_realsense(pipeline)
                ok = frame is not None
            else:
                ok, frame = cap.read()

            if not ok:
                continue

            fh, fw = frame.shape[:2]

            # ----- YOLO -----
            results = model.predict(
                frame,
                imgsz=args.imgsz,
                conf=args.conf,
                iou=args.iou,
                verbose=False
            )
            annotated = results[0].plot()

            key = cv2.waitKey(1) & 0xFF

            # ------------------------------------------------------------
            # S í‚¤ â†’ STT ìŠ¤ë ˆë“œ ì‹œì‘ (YOLO ë©ˆì¶”ì§€ ì•ŠìŒ)
            # ------------------------------------------------------------
            if key == ord('s') and not stt_state["running"]:
                print("ğŸ¤ STT ìŠ¤ë ˆë“œ ì‹¤í–‰")
                stt_state["running"] = True
                threading.Thread(
                    target=stt_thread,
                    args=(stt_state,),
                    daemon=True
                ).start()

            # ------------------------------------------------------------
            # YOLO íƒì§€ ê²°ê³¼ë¡œ 9ë¶„í•  ì•ˆë‚´
            # ------------------------------------------------------------
            target_object = stt_state["target"]

            if target_object:
                boxes = results[0].boxes
                if boxes:
                    for box in boxes:
                        cls_name = results[0].names[int(box.cls[0])]
                        if cls_name == target_object:

                            x1, y1, x2, y2 = box.xyxy[0]
                            cx = float((x1 + x2) / 2)
                            cy = float((y1 + y2) / 2)

                            region = grid_region(cx, cy, fw, fh)
                            speak = f"{target_object}ì€ {GRID_TEXT.get(region)}"

                            print("ğŸ“¢", speak)
                            tts_speak(speak)

                            stt_state["target"] = None
                            break

            # ----- í™”ë©´ ì¶œë ¥ -----
            if args.show:
                cv2.imshow("YOLO", annotated)

            if key == 27:
                break

    finally:
        if pipeline:
            pipeline.stop()
        if cap:
            cap.release()
        cv2.destroyAllWindows()


# =============================================================
if __name__ == "__main__":
    main()
