import argparse
import time
import threading
from typing import Optional
from queue import Queue

import cv2
import numpy as np
from ultralytics import YOLO

# -----------------------------
# RealSense import
# -----------------------------
try:
    import pyrealsense2 as rs
    REALSENSE_AVAILABLE = True
except ImportError:
    REALSENSE_AVAILABLE = False
    print("ê²½ê³ : pyrealsense2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. RealSense ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# -----------------------------
# STT / TTS
# -----------------------------
import speech_recognition as sr
from gtts import gTTS
from pydub import AudioSegment
import os


# =============================================================
# TTS í ì‹œìŠ¤í…œ (wav + aplay + ë¹ ë¥¸ ì†ë„ atempo)
# =============================================================
TTS_QUEUE = Queue()

def tts_worker():
    """ë¹ ë¥¸ TTS (ì†ë„ 1.5ë°°)"""
    while True:
        text = TTS_QUEUE.get()
        try:
            # gTTS â†’ mp3
            t = gTTS(text=text, lang='ko')
            t.save("tts_tmp.mp3")

            # mp3 â†’ wav
            sound = AudioSegment.from_mp3("tts_tmp.mp3")
            sound.export("tts_tmp.wav", format="wav")

            # wav ì†ë„ ë¹ ë¥´ê²Œ (1.5ë°°)
            os.system("ffmpeg -y -i tts_tmp.wav -filter:a 'atempo=1.5' tts_tmp_fast.wav 2>/dev/null")

            # ì¬ìƒ
            os.system("aplay -q tts_tmp_fast.wav")

        except Exception as e:
            print("TTS ì˜¤ë¥˜:", e)

        TTS_QUEUE.task_done()

threading.Thread(target=tts_worker, daemon=True).start()

def tts_speak(text):
    print("ğŸ”Š TTS ìš”ì²­:", text)
    TTS_QUEUE.put(text)


# =============================================================
# ì¡°ì‚¬ ì œê±° / í´ë˜ìŠ¤ ë§¤í•‘
# =============================================================
particles = [
    "ì´ë‘", "ë‘", "í•˜ê³ ", "ê³¼", "ì™€",
    "ì—ì„œ", "ìœ¼ë¡œ", "ë¡œ",
    "ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì—"
]

YOLO_CLASSES = [
    "airpods", "cell phone", "tissue", "mouse",
    "bottle", "glasses", "jelly", "card", "wallet",
    "lipbalm", "remocon", "pen", "applewatch"
]

SYNONYMS = {
    "ì—ì–´íŒŸ": "airpods",
    "ì´ì–´í°": "airpods",
    "í•¸ë“œí°": "cell phone",
    "íœ´ëŒ€í°": "cell phone",
    "í°": "cell phone",
    "í‹°ìŠˆ": "tissue",
    "íœ´ì§€": "tissue",
    "ë§ˆìš°ìŠ¤": "mouse",
    "ë¬¼ë³‘": "bottle",
    "ë³´í‹€": "bottle",
    "ì•ˆê²½": "glasses",
    "ì„ ê¸€ë¼ìŠ¤": "glasses",
    "ì ¤ë¦¬": "jelly",
    "ì¹´ë“œ": "card",
    "ì‹ ìš©ì¹´ë“œ": "card",
    "ì§€ê°‘": "wallet",
    "ë¦½ë°¤": "lipbalm",
    "ë¦½": "lipbalm",
    "ë¦¬ëª¨ì½˜": "remocon",
    "ë¦¬ëª¨ì»¨": "remocon",
    "íœ": "pen",
    "ë³¼íœ": "pen",
    "ì• í”Œì›Œì¹˜": "applewatch",
    "ì›Œì¹˜": "applewatch"
}


def split_particle(word: str):
    for p in particles:
        if word.endswith(p):
            return [word[:-len(p)], p]
    return [word]


def remove_particle(word: str):
    for p in particles:
        if word.endswith(p):
            return word[:-len(p)]
    return word


def map_to_class(text: str):
    tokens = []
    for w in text.split():
        tokens.extend(split_particle(w))
    for token in tokens:
        stem = remove_particle(token)
        if stem in SYNONYMS:
            return SYNONYMS[stem]
        if stem in YOLO_CLASSES:
            return stem
    return None


# =============================================================
# ğŸ”¥ 16ë¶„í•  ì•ˆë‚´ (4Ã—4)
# =============================================================
GRID_TEXT = {
    1: "1êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    2: "2êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    3: "3êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    4: "4êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    5: "5êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    6: "6êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    7: "7êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    8: "8êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    9: "9êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    10: "10êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    11: "11êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    12: "12êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    13: "13êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    14: "14êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    15: "15êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤.",
    16: "16êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤."
}

def grid_region(cx, cy, w, h):
    col = int(cx // (w / 4))   # 0~3
    row = int(cy // (h / 4))   # 0~3
    col = min(col, 3)
    row = min(row, 3)
    return row * 4 + col + 1   # 1~16


# =============================================================
# STT
# =============================================================
def stt_listen():
    r = sr.Recognizer()
    r.energy_threshold = 300

    with sr.Microphone() as mic:
        print("ğŸ¤ STT ëŒ€ê¸°ì¤‘â€¦ ë§í•˜ì„¸ìš”.")
        try:
            audio = r.listen(mic, timeout=5, phrase_time_limit=5)
        except:
            return ""
    try:
        text = r.recognize_google(audio, language='ko-KR')
        print("ğŸ—£ ì¸ì‹:", text)
        return text
    except:
        print("âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
        return ""


# =============================================================
# STT ìŠ¤ë ˆë“œ (ìë™ ì¬ì‹œì‘ ë²„ì „)
# =============================================================
def stt_thread(state):
    text = stt_listen()
    cls = map_to_class(text)

    if not text.strip():
        tts_speak("ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.")
        state["target"] = None
        state["running"] = True
        state["retry"] = True
        threading.Thread(target=stt_thread, args=(state,), daemon=True).start()
        return

    if not cls:
        tts_speak("ë¬´ìŠ¨ ë¬¼ê±´ì¸ì§€ ëª¨ë¥´ê² ì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.")
        state["target"] = None
        state["running"] = True
        state["retry"] = True
        threading.Thread(target=stt_thread, args=(state,), daemon=True).start()
        return

    print("ğŸ¯ ì°¾ëŠ” ê°ì²´:", cls)
    state["target"] = cls
    state["running"] = False
    state["retry"] = False
    state["searched_before"] = True



# =============================================================
# YOLO Args
# =============================================================
def parse_args():
    from pathlib import Path
    project_root = Path(__file__).parent.absolute()
    default_weights = project_root / "weights" / "best.pt"
    if not default_weights.exists():
        default_weights = project_root / "weights" / "yolov8l.pt"

    parser = argparse.ArgumentParser()
    parser.add_argument("--weights", type=str, default=str(default_weights))
    parser.add_argument("--source", type=str, default="realsense")
    parser.add_argument("--imgsz", type=int, default=1280)
    parser.add_argument("--conf", type=float, default=0.5)
    parser.add_argument("--iou", type=float, default=0.7)
    parser.add_argument("--device", type=str, default="cpu")
    parser.add_argument("--show", action="store_true")
    return parser.parse_args()


# =============================================================
# RealSense
# =============================================================
def init_realsense():
    if not REALSENSE_AVAILABLE:
        print("âŒ pyrealsense2 ì—†ìŒ â†’ RealSense ë¶ˆê°€")
        return None

    try:
        pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)
        pipeline.start(config)
        print("âœ… RealSense ì—°ê²° ì„±ê³µ!")
        return pipeline
    except Exception as e:
        print("âŒ RealSense ì—°ê²° ì‹¤íŒ¨:", e)
        return None


def get_frame_realsense(pipeline):
    try:
        frames = pipeline.wait_for_frames(timeout_ms=3000)
        f = frames.get_color_frame()
        if f:
            return np.asanyarray(f.get_data())
    except:
        return None
    return None



# =============================================================
# MAIN LOOP
# =============================================================
def main():
    args = parse_args()
    model = YOLO(args.weights)

    use_rs = args.source.lower() in ["realsense", "rs", "d435i"]
    pipeline = None
    cap = None

    # RealSense ì—°ê²° ë°˜ë³µ
    if use_rs:
        while pipeline is None:
            print("ğŸ”„ RealSense ì—°ê²° ì‹œë„ì¤‘â€¦")
            pipeline = init_realsense()
            if pipeline is None:
                print("âŒ ì‹¤íŒ¨. 5ì´ˆ í›„ ì¬ì‹œë„â€¦")
                time.sleep(5)
        print("ğŸ‰ RealSense ìµœì¢… ì—°ê²° ì„±ê³µ!")
    else:
        cap = cv2.VideoCapture(args.source)

    stt_state = {
        "target": None,
        "running": False,
        "retry": False,
        "searched_before": False
    }

    try:
        while True:

            # í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
            if use_rs:
                frame = get_frame_realsense(pipeline)
                ok = frame is not None
            else:
                ok, frame = cap.read()
            if not ok:
                continue

            fh, fw = frame.shape[:2]

            # YOLO ì¶”ë¡ 
            results = model.predict(
                frame,
                imgsz=args.imgsz,
                conf=args.conf,
                iou=args.iou,
                verbose=False
            )
            annotated = results[0].plot()

            key = cv2.waitKey(1) & 0xFF

            # =====================================================
            # S â†’ STT ìµœì´ˆ 1íšŒ ì‹¤í–‰
            # =====================================================
            if key == ord('s'):
                if not stt_state["running"]:
                    tts_speak("ì–´ë–¤ ë¬¼ê±´ì„ ì°¾ì„ê¹Œìš”?")
                    stt_state["running"] = True
                    threading.Thread(target=stt_thread, args=(stt_state,), daemon=True).start()

            # =====================================================
            # YOLO ê²°ê³¼ â†’ ë¬¼ê±´ ìœ„ì¹˜ ì•ˆë‚´ (16ë¶„í• )
            # =====================================================
            target_object = stt_state["target"]

            if target_object:
                for box in results[0].boxes:
                    cls_name = results[0].names[int(box.cls[0])]
                    if cls_name == target_object:

                        x1, y1, x2, y2 = box.xyxy[0]
                        cx = float((x1 + x2) / 2)
                        cy = float((y1 + y2) / 2)

                        region = grid_region(cx, cy, fw, fh)
                        location_text = GRID_TEXT.get(region)

                        tts_speak(f"{target_object}ì€ {location_text}")

                        stt_state["target"] = None
                        stt_state["running"] = False
                        break

            if args.show:
                cv2.imshow("YOLO", annotated)

            if key == 27:
                break

    finally:
        if pipeline:
            pipeline.stop()
        if cap:
            cap.release()
        cv2.destroyAllWindows()



# =============================================================
if __name__ == "__main__":
    main()
