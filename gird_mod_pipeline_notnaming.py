import argparse
import time
import threading
from queue import Queue

import cv2
import numpy as np
from ultralytics import YOLO

try:
    import pyrealsense2 as rs
    REALSENSE_AVAILABLE = True
except ImportError:
    REALSENSE_AVAILABLE = False

import speech_recognition as sr
from gtts import gTTS
from pydub import AudioSegment
import os


# ======================================================================
# TTS
# ======================================================================
TTS_QUEUE = Queue()

def tts_worker():
    while True:
        text = TTS_QUEUE.get()
        try:
            t = gTTS(text=text, lang='ko')
            t.save("tts_tmp.mp3")

            sound = AudioSegment.from_mp3("tts_tmp.mp3")    
            sound.export("tts_tmp.wav", format="wav")

            os.system("ffmpeg -y -i tts_tmp.wav -filter:a 'atempo=1.5' tts_tmp_fast.wav 2>/dev/null")
            os.system("aplay -q tts_tmp_fast.wav")

        except Exception as e:
            print("TTS ì˜¤ë¥˜:", e)

        TTS_QUEUE.task_done()

threading.Thread(target=tts_worker, daemon=True).start()

def tts_speak(text):
    print("ğŸ”Š:", text)
    TTS_QUEUE.put(text)


# ======================================================================
# ì¡°ì‚¬/í´ë˜ìŠ¤ ë§¤í•‘
# ======================================================================
particles = [
    "ì´ë‘","ë‘","í•˜ê³ ","ê³¼","ì™€",
    "ì—ì„œ","ìœ¼ë¡œ","ë¡œ",
    "ì€","ëŠ”","ì´","ê°€","ì„","ë¥¼","ì—"
]

YOLO_CLASSES = [
    "airpods","cell phone","tissue","mouse",
    "bottle","glasses","jelly","card","wallet",
    "lipbalm","remocon","pen","applewatch"
]

SYNONYMS = {
    "ì—ì–´íŒŸ":"airpods",
    "ì´ì–´í°":"airpods",
    "í•¸ë“œí°":"cell phone",
    "íœ´ëŒ€í°":"cell phone",
    "í°":"cell phone",
    "í‹°ìŠˆ":"tissue",
    "íœ´ì§€":"tissue",
    "ë§ˆìš°ìŠ¤":"mouse",
    "ë¬¼ë³‘":"bottle",
    "ë³´í‹€":"bottle",
    "ì•ˆê²½":"glasses",
    "ì„ ê¸€ë¼ìŠ¤":"glasses",
    "ì ¤ë¦¬":"jelly",
    "ì¹´ë“œ":"card",
    "ì‹ ìš©ì¹´ë“œ":"card",
    "ì§€ê°‘":"wallet",
    "ë¦½ë°¤":"lipbalm",
    "ë¦½":"lipbalm",
    "ë¦¬ëª¨ì½˜":"remocon",
    "ë¦¬ëª¨ì»¨":"remocon",
    "íœ":"pen",
    "ë³¼íœ":"pen",
    "ì• í”Œì›Œì¹˜":"applewatch",
    "ì›Œì¹˜":"applewatch"
}

def split_particle(word):
    for p in particles:
        if word.endswith(p):
            return [word[:-len(p)], p]
    return [word]

def remove_particle(word):
    for p in particles:
        if word.endswith(p):
            return word[:-len(p)]
    return word


def josa_eunneun(word: str):
    if not word:
        return "ì€"
    last = word[-1]
    if "ê°€" <= last <= "í£":
        jong = (ord(last) - ord("ê°€")) % 28
        return "ì€" if jong != 0 else "ëŠ”"
    return "ëŠ”"


def map_to_class(text):
    tokens = []
    for w in text.split():
        tokens.extend(split_particle(w))

    for token in tokens:
        stem = remove_particle(token)

        if stem in SYNONYMS:
            return SYNONYMS[stem], stem
        if stem in YOLO_CLASSES:
            return stem, stem

    return None, None


# ======================================================================
# 16êµ¬ì—­ + ì„¸ë¶„í• 
# ======================================================================
SUBDIV_TARGETS = {6, 7, 10, 11}

GRID_TEXT = {
    1:"ì†ŒíŒŒ ì˜¤ë¥¸ìª½ ëì— ìˆìŠµë‹ˆë‹¤.",
    2:"ì§‘ ì¤‘ì•™ í•˜ë‹¨ì— ìˆìŠµë‹ˆë‹¤.",
    3:"ì§‘ ì¤‘ì•™ í•˜ë‹¨ì— ìˆìŠµë‹ˆë‹¤.",
    4:"ì™€ì¸ì…€ëŸ¬ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    5:"ì†ŒíŒŒ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    6:"ì§‘ ì¤‘ì•™ì— ìˆìŠµë‹ˆë‹¤",
    7:"ì§‘ ì¤‘ì•™ì— ìˆìŠµë‹ˆë‹¤",
    8:"ì™€ì¸ì…€ëŸ¬ì™€ TV ì‚¬ì´ì— ìˆìŠµë‹ˆë‹¤.",
    9:"ì†ŒíŒŒ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    10:"ì§‘ ì¤‘ì•™ì— ìˆìŠµë‹ˆë‹¤.",
    11:"ì§‘ ì¤‘ì•™ì— ìˆìŠµë‹ˆë‹¤.",
    12:"TV ì•ì— ìˆìŠµë‹ˆë‹¤.",
    13:"ì†ŒíŒŒì™€ ì¹¨ëŒ€ ì‚¬ì´ì— ìˆìŠµë‹ˆë‹¤.",
    14:"ì¹¨ëŒ€ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    15:"ì„œëì¥ ì•ì— ìˆìŠµë‹ˆë‹¤.",
    16:"TVì™€ ì„œëì¥ ì‚¬ì´ì— ìˆìŠµë‹ˆë‹¤."
}

def region_16(cx, cy, w, h):
    col = int(cx // (w / 4))
    row = int(cy // (h / 4))
    col = min(col, 3)
    row = min(row, 3)
    return row * 4 + col + 1

def sub_region_2x2(cx, cy, w, h, region16):
    if region16 not in SUBDIV_TARGETS:
        return None

    r = region16 - 1
    row = r // 4
    col = r % 4

    x1 = int(w * col / 4)
    y1 = int(h * row / 4)
    x2 = int(w * (col + 1) / 4)
    y2 = int(h * (row + 1) / 4)

    mx = (x1 + x2) // 2
    my = (y1 + y2) // 2

    horiz = "ì™¼ìª½" if cx < mx else "ì˜¤ë¥¸ìª½"
    vert  = "ìœ„" if cy < my else "ì•„ë˜"

    return f"{horiz} {vert}"


# ======================================================================
# ğŸ”¥ STT (ì•ˆì „í•œ ìë™ ì¬ì‹œë„ ë²„ì „)
# ======================================================================
def stt_thread(state):
    r = sr.Recognizer()
    r.energy_threshold = 300

    tts_speak("ì–´ë–¤ ë¬¼ê±´ì„ ì°¾ì„ê¹Œìš”?")

    while True:
        print("ğŸ¤ STT ëŒ€ê¸°ì¤‘â€¦")

        # --- ë…¹ìŒ ---
        try:
            with sr.Microphone() as mic:
                audio = r.listen(mic, timeout=5, phrase_time_limit=5)
        except Exception:
            print("âŒ ë…¹ìŒ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„...")
            tts_speak("ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.")
            time.sleep(0.5)
            continue

        # --- ìŒì„± ì¸ì‹ ---
        try:
            text = r.recognize_google(audio, language='ko-KR')
            print("ğŸ—£ ì¸ì‹:", text)
        except Exception:
            print("âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„...")
            tts_speak("ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.")
            time.sleep(0.5)
            continue

        # --- í´ë˜ìŠ¤ ë§¤í•‘ ---
        cls, user_word = map_to_class(text)

        if not cls:
            print("âŒ ë§¤í•‘ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„...")
            tts_speak("ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.")
            time.sleep(0.5)
            continue

        # --- ì„±ê³µ ---
        print(f"ğŸ¯ ì°¾ëŠ” ê°ì²´: {cls} (ì‚¬ìš©ìë‹¨ì–´: {user_word})")
        state["target"] = cls
        state["user_word"] = user_word
        state["running"] = False
        return  # ìŠ¤ë ˆë“œ ì¢…ë£Œ


# ======================================================================
# RealSense
# ======================================================================
def init_realsense():
    if not REALSENSE_AVAILABLE:
        print("âŒ pyrealsense2 ì—†ìŒ")
        return None
    try:
        pipe = rs.pipeline()
        cfg = rs.config()
        cfg.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)
        pipe.start(cfg)
        print("âœ… RealSense ì—°ê²° ì„±ê³µ!")
        return pipe
    except Exception as e:
        print("âŒ RealSense ì˜¤ë¥˜:", e)
        return None

def get_frame_realsense(pipe):
    try:
        frames = pipe.wait_for_frames(timeout_ms=3000)
        f = frames.get_color_frame()
        if f:
            return np.asanyarray(f.get_data())
    except:
        return None
    return None


# ======================================================================
# MAIN
# ======================================================================
def parse_args():
    p = argparse.ArgumentParser()
    p.add_argument("--weights", type=str, default="last.pt")
    p.add_argument("--source", type=str, default="rs")
    p.add_argument("--imgsz", type=int, default=640)
    p.add_argument("--conf", type=float, default=0.5)
    p.add_argument("--iou", type=float, default=0.5)
    p.add_argument("--show", action="store_true")
    return p.parse_args()


def main():
    args = parse_args()
    model = YOLO(args.weights)

    use_rs = args.source.lower() in ["rs", "realsense", "d435i"]
    pipeline = None

    if use_rs:
        while pipeline is None:
            print("ğŸ”„ RealSense ì—°ê²° ì‹œë„ì¤‘")
            pipeline = init_realsense()
            if pipeline is None:
                print("âŒ ì‹¤íŒ¨, 5ì´ˆ í›„ ì¬ì‹œë„")
                time.sleep(5)
    else:
        pipeline = cv2.VideoCapture(args.source)

    stt_state = {
        "target": None,
        "user_word": None,
        "running": False
    }

    try:
        while True:

            # í”„ë ˆì„ ì…ë ¥
            if use_rs:
                frame = get_frame_realsense(pipeline)
            else:
                _, frame = pipeline.read()

            if frame is None:
                continue

            h, w = frame.shape[:2]

            results = model.predict(
                frame, imgsz=args.imgsz, conf=args.conf, iou=args.iou, verbose=False
            )
            annotated = results[0].plot()

            key = cv2.waitKey(1) & 0xFF

            # ------------------------------------------------------------------
            # ğŸ”¥ STT ì‹œì‘ (s ëˆ„ë¥¼ ë•Œë§Œ)
            # ------------------------------------------------------------------
            if key == ord('s') and not stt_state["running"]:
                stt_state["running"] = True
                threading.Thread(target=stt_thread, args=(stt_state,), daemon=True).start()

            # ------------------------------------------------------------------
            # ğŸ”¥ YOLO íƒ€ê²Ÿ ê²€ìƒ‰
            # ------------------------------------------------------------------
            if stt_state["target"]:
                yolo_target = stt_state["target"]
                user_word = stt_state["user_word"]

                for box in results[0].boxes:
                    cname = results[0].names[int(box.cls[0])]

                    if cname == yolo_target:

                        x1, y1, x2, y2 = box.xyxy[0]
                        cx = float((x1 + x2) / 2)
                        cy = float((y1 + y2) / 2)

                        region16 = region_16(cx, cy, w, h)
                        loc_base = GRID_TEXT.get(region16)

                        # ì„¸ë¶„í•  íŒë‹¨
                        sub = sub_region_2x2(cx, cy, w, h, region16)

                        if sub:
                            loc_final = f"{region16}ë²ˆ êµ¬ì—­ {sub}ì— ìˆìŠµë‹ˆë‹¤."
                        else:
                            loc_final = loc_base

                        josa = josa_eunneun(user_word)
                        tts_speak(f"{user_word}{josa} {loc_final}")

                        stt_state["target"] = None
                        break

            if args.show:
                cv2.imshow("YOLO", annotated)

            if key == 27:
                break

    finally:
        try:
            pipeline.stop()
        except:
            pass
        cv2.destroyAllWindows()


if __name__ == "__main__":
    main()
